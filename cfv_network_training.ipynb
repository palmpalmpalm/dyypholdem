{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdZSV34gUrX4",
        "outputId": "87c54062-3327-4810-823d-e0caab435894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu May 26 20:51:29 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   48C    P0    32W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "W8kpAvrQUwGd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch \n",
        "from torch import nn \n",
        "import torch.nn.functional as F \n",
        "from torch import optim \n",
        "import torchvision \n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "from tqdm.notebook import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRhSFpEfRGUX",
        "outputId": "4873004d-a34e-4315-dd6e-ff4c869528d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm--YxMYOvt2"
      },
      "source": [
        "# Move data from drive to colab instance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fVktsmkn0gI",
        "outputId": "c29836c4-82d0-489b-cb96-d925a410fd18"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/river_data2.zip', 1)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from distutils.file_util import copy_file\n",
        "copy_file(\"/content/drive/Shareddrives/Pattern/river_data2.zip\", \"/content\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JY0doiK8etct"
      },
      "outputs": [],
      "source": [
        "# create river dir\n",
        "!mkdir river_samples"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "l3Kt5z-eevqE"
      },
      "outputs": [],
      "source": [
        "# unzip file\n",
        "import shutil\n",
        "shutil.unpack_archive('/content/river_data2.zip', '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Xji6ZSlge9AM",
        "outputId": "5e47761e-1e31-4bd0-c6b6-d61fc2a38605"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/training_samples'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# move file\n",
        "import shutil\n",
        "shutil.move('/content/content/river_samples/content/training_samples', '/content')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1uvHM29aft2C",
        "outputId": "dbfe48cd-b430-4703-d13a-0d90991cc329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "116682.0\n"
          ]
        }
      ],
      "source": [
        "# count file\n",
        "import os\n",
        "\n",
        "path, dirs, files = next(os.walk(\"/content/training_samples/river/bucketed\"))\n",
        "file_count = len(files)\n",
        "print(file_count/2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "IQIpLzvJXi9c"
      },
      "outputs": [],
      "source": [
        "root = '/content/training_samples/river/bucketed'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eUD8XJkdIxMw"
      },
      "source": [
        "# Dataset / DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "IX5Ad5-PIxM4"
      },
      "outputs": [],
      "source": [
        "# Config batch size\n",
        "\n",
        "train_batch_size = 1000\n",
        "val_batch_size = 1000\n",
        "test_batch_size = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "W60VQB2dIxM4"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rZvoYmNnIxM4"
      },
      "outputs": [],
      "source": [
        "# Dataset for CFV data \n",
        "\n",
        "class CFVDataset(Dataset):\n",
        "    def __init__(self, x, y, preprocess=None):\n",
        "        self.x = x\n",
        "        self.y = y\n",
        "        # self.x = glob.glob(os.path.join(root, '*.inputs'))\n",
        "        # self.y = glob.glob(os.path.join(root, '*.targets'))\n",
        "        self.preprocess = preprocess\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x_data = torch.load(self.x[idx],map_location=torch.device(device))\n",
        "        y_data = torch.load(self.y[idx],map_location=torch.device(device))\n",
        "        mask =  torch.clone(y_data)\n",
        "        mask[mask != 0] = 1\n",
        "\n",
        "        return x_data, y_data, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "JG73SjImIxM4"
      },
      "outputs": [],
      "source": [
        "data_x = sorted(glob.glob(os.path.join(root, '*.inputs')))\n",
        "data_y = sorted(glob.glob(os.path.join(root, '*.targets')))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_x_train = data_x[:int(len(data_x)*0.8)]\n",
        "data_x_val = data_x[int(len(data_x)*0.8):int(len(data_x)*0.9)]\n",
        "data_x_test = data_x[int(len(data_x)*0.9):]"
      ],
      "metadata": {
        "id": "GG0Ju64wWN5W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4NZ_tEexIxM5"
      },
      "outputs": [],
      "source": [
        "data_y_train = data_y[:int(len(data_y)*0.8)]\n",
        "data_y_val = data_y[int(len(data_y)*0.8):int(len(data_x)*0.9)]\n",
        "data_y_test = data_y[int(len(data_y)*0.9):]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "5nVnvMEAIxM5"
      },
      "outputs": [],
      "source": [
        "# Train and Val data loader\n",
        "\n",
        "train_dataset = CFVDataset(x=data_x_train,y=data_y_train)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=train_batch_size, shuffle=True, pin_memory=False)\n",
        "val_dataset = CFVDataset(x=data_x_val,y=data_y_val)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=val_batch_size, shuffle=False, pin_memory=False)\n",
        "test_dataset = CFVDataset(x=data_x_test,y=data_y_test)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=test_batch_size, shuffle=False, pin_memory=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vZJxoFmd4Uo"
      },
      "source": [
        "# Loss Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "vLgLnrxt19PN"
      },
      "outputs": [],
      "source": [
        "def smoothL1LossForward(outputs, targets):\n",
        "    # Smooth L1 Loss for two vectors\n",
        "    n = torch.abs(outputs - targets)\n",
        "    beta = 1\n",
        "    cond = n < beta\n",
        "    z = torch.where(cond, 0.5 * n ** 2 / beta, n - 0.5 * beta)\n",
        "    return z.mean()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yrQxHOrXdPIc"
      },
      "outputs": [],
      "source": [
        "class MaskedHuberLoss(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(MaskedHuberLoss, self).__init__()\n",
        "\n",
        "\n",
        "    def forward(self, outputs, targets, masks):\n",
        "        # Reshape tesnsors\n",
        "        outputs = outputs.squeeze(1)\n",
        "        targets = targets.squeeze(1)\n",
        "        masks = masks.squeeze(1)\n",
        "\n",
        "        batch_size = outputs.size(0)\n",
        "        feature_size = outputs.size(1)\n",
        "\n",
        "        # Zero out the outputs/target so that the error does not depend on these\n",
        "        outputs.mul_(masks)\n",
        "        targets.mul_(masks)\n",
        "        \n",
        "        loss = smoothL1LossForward(outputs, targets)\n",
        "        \n",
        "        # If the batch size has changed, create new storage for the sum, otherwise reuse\n",
        "        mask_placeholder = torch.zeros_like(masks).to(device)\n",
        "        mask_sum = torch.FloatTensor(batch_size).fill_(0).to(device)\n",
        "        mask_multiplier = mask_sum.clone().fill_(0).view(-1, 1).to(device)\n",
        "\n",
        "        # Compute mask sum for each batch\n",
        "        mask_placeholder.copy_(masks)\n",
        "        mask_sum = mask_placeholder.sum(dim=1, keepdim=True)\n",
        "        \n",
        "\n",
        "        # Mask multiplier - note that mask is 1 for impossible features\n",
        "        mask_multiplier = mask_multiplier.fill_(feature_size)\n",
        "        mask_multiplier = mask_multiplier.sub_(mask_sum)\n",
        "        mask_multiplier = mask_multiplier.div_(feature_size)\n",
        "        \n",
        "        # Multiply to get a new losss\n",
        "        # Loss is not really computed batch-wise correctly,\n",
        "        # But that does not really matter now since gradients are correct\n",
        "        loss_multiplier = (batch_size * feature_size) / (batch_size * feature_size - mask_sum.sum() )\n",
        "        new_loss = loss_multiplier * loss\n",
        "\n",
        "        return new_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "Dv2Q8OiO66Ab"
      },
      "outputs": [],
      "source": [
        "loss_function = MaskedHuberLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywKmCkAwcEMO"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "GysoZ7qpclFq"
      },
      "outputs": [],
      "source": [
        "# Config input and output size // must match the bucketed size\n",
        "ip_size = train_dataset[0][0].shape[1]\n",
        "op_size = train_dataset[0][1].shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QcE8yOvPOlX-"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "09Qaor8DcDJi"
      },
      "outputs": [],
      "source": [
        "# Baseline model from the paper\n",
        "\n",
        "class BaselineNN(nn.Module):\n",
        "    def __init__(self, hidden_size=500,input_size=ip_size,output_size=op_size):\n",
        "        super(BaselineNN, self).__init__()\n",
        "        \n",
        "        model = nn.Sequential(\n",
        "          nn.Linear(input_size, hidden_size),\n",
        "          nn.PReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.PReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.PReLU(),\n",
        "          nn.Linear(hidden_size, hidden_size),\n",
        "          nn.PReLU(),\n",
        "          nn.Linear(hidden_size, output_size),\n",
        "        )\n",
        "\n",
        "        self.model = model\n",
        "        self.input_size = input_size\n",
        "        self.output_size = output_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Normal ff\n",
        "        feedforward = self.model(x)\n",
        "\n",
        "        # Zerosum part\n",
        "        ranges = torch.narrow(x,2, 0, self.output_size)\n",
        "        batch1 = feedforward\n",
        "        batch2 = torch.moveaxis(ranges,1,2)\n",
        "        estimated_value = torch.bmm(batch1, batch2).squeeze(2)        \n",
        "        estimated_value = estimated_value.repeat(1, self.output_size).unsqueeze(1)\n",
        "        estimated_value = torch.mul(estimated_value, -0.5)\n",
        "        final_mlp = torch.add(feedforward, estimated_value)\n",
        "\n",
        "        return final_mlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAIHfuCz3K1m"
      },
      "source": [
        "# Initialize the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Eu2nVnRdgNy",
        "outputId": "f0abfffd-18a0-41de-d752-0e0fd867b3b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BaselineNN(\n",
            "  (model): Sequential(\n",
            "    (0): Linear(in_features=1009, out_features=500, bias=True)\n",
            "    (1): PReLU(num_parameters=1)\n",
            "    (2): Linear(in_features=500, out_features=500, bias=True)\n",
            "    (3): PReLU(num_parameters=1)\n",
            "    (4): Linear(in_features=500, out_features=500, bias=True)\n",
            "    (5): PReLU(num_parameters=1)\n",
            "    (6): Linear(in_features=500, out_features=500, bias=True)\n",
            "    (7): PReLU(num_parameters=1)\n",
            "    (8): Linear(in_features=500, out_features=1008, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Init baseline model\n",
        "\n",
        "baseline_model = BaselineNN()\n",
        "baseline_model.to(device)\n",
        "print(baseline_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KmkHLPBeOTd"
      },
      "source": [
        "# Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l75GSFqJeagE"
      },
      "outputs": [],
      "source": [
        "# Hyperparameters and other configs\n",
        "\n",
        "config = {\n",
        "    'architecture': 'feedforward',\n",
        "    'lr': 0.001,\n",
        "    'scheduler_factor': 0.2,\n",
        "    'scheduler_patience': 2,\n",
        "    'scheduler_min_lr': 1e-4,\n",
        "    'epochs': 50\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evlgT087ePpI"
      },
      "outputs": [],
      "source": [
        "# Use Adam as optmizer\n",
        "\n",
        "optimizer = torch.optim.Adam(baseline_model.parameters(), lr=config['lr'])\n",
        "\n",
        "# Just simply scheduler\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "    optimizer, \n",
        "    'min', \n",
        "    factor=config['scheduler_factor'], \n",
        "    patience=config['scheduler_patience'], \n",
        "    min_lr=config['scheduler_min_lr']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEqpH8NOeE1j"
      },
      "source": [
        "# Training and Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "btNKlAPZL0bk"
      },
      "source": [
        "## Baseline Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXaSoYLRM1yY"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NdnXrlJx3hhw"
      },
      "outputs": [],
      "source": [
        "# Start training baseline model\n",
        "\n",
        "model_name = 'baseline_model'\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "\n",
        "for epoch in range(config['epochs']):  # loop over the dataset multiple times\n",
        "    \n",
        "    # Training\n",
        "    train_loss = []\n",
        "    current_lr = optimizer.param_groups[0]['lr']\n",
        "\n",
        "    # Flag model as training. \n",
        "    baseline_model.train()\n",
        "\n",
        "    print(f\"Training epoch {epoch+1}...\")\n",
        "    print(f\"Current LR: {current_lr}\")\n",
        "\n",
        "    for i, (inputs, targets, masks) in enumerate(tqdm(train_dataloader)):\n",
        "        # Transfer data from cpu to gpu\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Reset the gradient\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Predict\n",
        "        y_pred = baseline_model(inputs)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_function(y_pred, targets, masks)\n",
        "\n",
        "        # Compute gradient\n",
        "        loss.backward()\n",
        "        \n",
        "        # Update parameters\n",
        "        optimizer.step()\n",
        "\n",
        "        # Log stuff\n",
        "        train_loss.append(loss)\n",
        "        \n",
        "    avg_train_loss = torch.stack(train_loss).mean().item()\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    print(f\"Epoch {epoch+1} train loss: {avg_train_loss:.4f}\")\n",
        "    \n",
        "    # Validation\n",
        "    baseline_model.eval()\n",
        "    with torch.no_grad(): # No gradient is required during validation\n",
        "        print(f\"Validating epoch {epoch+1}\")\n",
        "        val_loss = []\n",
        "        for i, (inputs, y_true, masks) in enumerate(tqdm(val_dataloader)):\n",
        "            # Transfer data from cpu to gpu\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "            \n",
        "            # Predict\n",
        "            y_pred = baseline_model(inputs)\n",
        "\n",
        "            # Calculate loss\n",
        "            loss = loss_function(y_pred, y_true, masks)\n",
        "\n",
        "            # Log stuff\n",
        "            val_loss.append(loss)\n",
        "        \n",
        "        avg_val_loss = torch.stack(val_loss).mean().item()\n",
        "        val_losses.append(avg_val_loss)\n",
        "        print(f\"Epoch {epoch+1} val loss: {avg_val_loss:.4f}\")\n",
        "\n",
        "        # LR adjustment with scheduler\n",
        "        scheduler.step(avg_val_loss)\n",
        "\n",
        "        # Save checkpoint if val_loss is the best we got\n",
        "        best_val_loss = np.inf if epoch == 0 else min(val_losses[:-1])\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            # Save whatever you want\n",
        "            state = {\n",
        "                'epoch': epoch,\n",
        "                'model': baseline_model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'train_loss': avg_train_loss,\n",
        "                'val_loss': avg_val_loss,\n",
        "                'best_val_loss': best_val_loss,\n",
        "            }\n",
        "            \n",
        "            print(f\"Saving new best model..\")\n",
        "            torch.save(state, f'/content/drive/Shareddrives/Pattern/model/{model_name}_{calendar.timegm(datetime.utcnow().utctimetuple())}.pth.tar')\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_gzbVAQL8DM"
      },
      "source": [
        "### Train and Val loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l1X-P_M_lIYZ"
      },
      "outputs": [],
      "source": [
        "# Plot trian loss and val loss\n",
        "\n",
        "plt.plot(train_losses, label='Train Loss', color='b')\n",
        "plt.plot(val_losses, label='Val Loss', color='r')\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Train and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "P-sbCFuVd7V2"
      },
      "outputs": [],
      "source": [
        "# Save loss log\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "loss_df = pd.DataFrame({'train' : train_losses,\n",
        "                        'val' : val_losses})\n",
        "loss_df.to_csv(f'/content/drive/Shareddrives/Pattern/model/{model_name}_{calendar.timegm(datetime.utcnow().utctimetuple())}.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsvgE3TUNpSG"
      },
      "source": [
        "### Save & Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "IbIayuNxrfHl"
      },
      "outputs": [],
      "source": [
        "# from datetime import datetime\n",
        "# import calendar\n",
        "# torch.save(baseline_model.state_dict(), f'/content/drive/Shareddrives/Pattern/model/{model_name}_{calendar.timegm(datetime.utcnow().utctimetuple())}.pth.tar')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "7S0ZpZaTNBWx"
      },
      "outputs": [],
      "source": [
        "# best_model_path = \"\"\n",
        "\n",
        "# best_baseline_model = BaselineNN()\n",
        "# best_baseline_model = torch.load(best_model_path)\n",
        "# best_baseline_model.eval()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OR4fUeKjOAki"
      },
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VZoSQDsJoQV3"
      },
      "outputs": [],
      "source": [
        "# Test inference\n",
        "with torch.no_grad():\n",
        "    baseline_model.eval()\n",
        "    result = baseline2_model(val_dataset[0][0].unsqueeze(1))\n",
        "\n",
        "torch.set_printoptions(threshold=10_000)\n",
        "print(val_dataset[0][1])\n",
        "print(\"-------\")\n",
        "print(result[0][0].mul_(val_dataset[0][2].squeeze(0)))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "G0IazLa2b4ib",
        "oqlk539kSvzZ",
        "IhWqW-1OLx2i"
      ],
      "machine_shape": "hm",
      "name": "cfv_network_training",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}